---
title: "GS Assignment Reference"
author: "Guy Schnidrig, Beatriz Vidondo"
toc: true
toc-depth: 4
toc-location: left
format: 
  html:
    self-contained: true
    code-link: true
    code-fold: show
number-sections: true
editor: source
theme:
  light: flatly
  dark: darkly
---

This is a reference book for [Basic Statistics and Projects in R](https://zuw.me/kurse/dt.php?kid=4474) course of the [Public Health Sciences Course Program](https://www.medizin.unibe.ch/studies/study_programs/phs_course_program) at the [University of Bern](https://www.unibe.ch/).

```{r setup, include=FALSE, echo=F, warning=FALSE, message=FALSE}
# Set language
Sys.setenv(LANG = "en")

# Clear memory
rm(list=ls())
gc()

# Load libraries
library_names <- c("tidyverse", "knitr", "downlit","palmerpenguins", "ggcorrplot","flextable", "ggpubr", "GGally", "performance", "rstatix", "datarium", "PairedData")

lapply(library_names, function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x)
    library(x, character.only = TRUE)
  }
})

# Set non-scientific notation
options(scipen = 999)
```

## Descriptive statistics

### Data types

In R, variables can possess diverse types. For instance, it is crucial to differentiate between numbers and character strings, as well as tables and plain lists of numbers. The `class` function aids us in identifying the specific object type we are dealing with.

```{r}
x <- 42
class(x)
```

```{r}
y <- "apple"
class(y)
```

#### Data frames

In R, the prevalent approach for storing data frames involves utilizing a data frame. In terms of conceptualization, a data frame can be envisioned as a tabular structure where rows represent observations and columns define the various variables reported for each observation. Data frames prove highly advantageous for data frames due to their ability to combine different data types into a single object. To load the palmerpenguins^[1](https://allisonhorst.github.io/palmerpenguins/)^ data set into a data frame, we can use the `data` function in R. The data set that contains measurements of penguins from three different species.

```{r}
data(penguins)
```

![](https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png){fig-align="center"}

We can now check the class of the object penguins. The `tbl_df` class is a subclass of `data.frame`, created in order to have different default behavior. The colloquial term "tibble" refers to a data frame that has the `tbl_df` class. Tibble is the central data structure for the set of packages known as the [tidyverse](https://www.tidyverse.org/packages/).

```{r}
class(penguins)

```

Now we can inspect the first 10 rows with `head`

```{r}
head(penguins, 10)
```

The `str` function in R provides a concise and informative display of the internal structure of an R object.

```{r}
str(penguins)
```

### Mean

To calculate the mean of a variable in R, you can employ `mean`

```{r}
x = 1:10
mean(x)
```

We can calculate the mean of the variable "Bill length" in the penguin data set, by combining the `mean` and `summarise`. Because we have some NA values specify the `na.rm` argument of `mean`.

![](https://allisonhorst.github.io/palmerpenguins/reference/figures/culmen_depth.png){fig-align="center"}

```{r}
penguins %>%
  summarise(Mean_Bill_Length = mean(bill_length_mm, na.rm = TRUE)) 
```

There are three different species in the penguins data set. To calculate the mean for each species we use `group_by`. Additionally we can use `kable` to format the output table.

```{r}
penguins %>%
  group_by(species) %>%                        
  summarise(Mean_Bill_Length = mean(bill_length_mm, na.rm = TRUE)) %>%
  kable(digits = 2)
```

### Median

To calculate the median we can replicate the code from above and insert the function `median`.

```{r}
penguins %>%
  group_by(species) %>%                        
  summarise(Mean_Bill_Length = mean(bill_length_mm, na.rm = TRUE),
            Median_Bill_Length = median(bill_length_mm, na.rm = TRUE)) %>%
  kable(digits = 2)
```

### Variance

`var` computes the variance of `x` and `y` if these are vectors.

```{r}
penguins %>%
  group_by(species) %>%                        
  summarise(Mean_Bill_Length = mean(bill_length_mm, na.rm = TRUE),
            Median_Bill_Length = median(bill_length_mm, na.rm = TRUE),
            Variance_Bill_Length = var(bill_length_mm, na.rm = TRUE)) %>%
  kable(digits = 2)
```

### Standard deviation

```{r}
penguins %>%
  group_by(species) %>%                        
  summarise(Mean_Bill_Length = mean(bill_length_mm, na.rm = TRUE),
            Median_Bill_Length = median(bill_length_mm, na.rm = TRUE),
            Variance_Bill_Length = var(bill_length_mm, na.rm = TRUE),
            SD__Bill_Length = sd(bill_length_mm, na.rm = TRUE)) %>%
  kable(digits = 2)
```

### The Interquartile Range


```{r}
summary_stat <- penguins %>%
  group_by(species) %>%                        
  summarise(Mean_Bill_Length = mean(bill_length_mm, na.rm = TRUE),
            Median_Bill_Length = median(bill_length_mm, na.rm = TRUE),
            Variance_Bill_Length = var(bill_length_mm, na.rm = TRUE),
            SD_Bill_Length = sd(bill_length_mm, na.rm = TRUE),
            IQR_Bill_Length = IQR(bill_length_mm, na.rm = TRUE))

summary_stat %>%
  kable(digits = 2)
```

### Correlation

The `cor` function computes the correlation coefficient, which measures the strength and direction of the linear relationship between two numeric variables. If your data contains missing values, you can handle them appropriately when calculating the correlation in R. The `cor` function has an argument called `use`, which allows you to specify how to handle missing values. For this example we only include rows with complete observations.

```{r}
cor_matrix <- penguins %>% 
  dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %>%
  cor(use = "complete.obs")

cor_matrix %>%
  kable(digits = 2)
```

## Data visualization

In order to utilize ggplot2, it is necessary to acquire familiarity with multiple functions and arguments. Remembering all of these can be challenging, hence we strongly advise keeping the ggplot2 cheat sheet accessible. You can obtain a copy from this [link](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf).

With ggplot we have many ways to customize the look of our plot. Try to experiment with: `fill` `color` `xlab` `ylab` `ggtitle` `labs` `xlim` `ylim` `scale_fill_manual` `scale_color_manual` `theme` `theme_bw`.

### Histogram

Histograms are an easy way to see how your data is distributed. They provide a visual representation of the frequency or count of data points falling within specific intervals, known as bins.

```{r, warning = FALSE}
penguins %>%
  ggplot(aes(bill_length_mm)) +
  geom_histogram(color = "black",
                 fill = "steelblue", 
                 bins = 30) + 
  theme_bw()
```

Alternatively you can use `geom_density` to get a quick overview over the distribution.

```{r, warning = FALSE}
penguins %>%
  ggplot(aes(bill_length_mm)) +
  geom_density(color = "black",
                 fill = "steelblue", 
                 bins = 30) + 
  theme_bw()
```

### Box plot

Box plots, also known as box-and-whisker plots, are useful statistical tools for visualizing and summarizing the distribution of a data set. They provide a concise summary of several important characteristics of the data, including the center, spread, skewness, and potential outliers.

```{r, warning=FALSE}
penguins %>%
  ggplot(aes(x = species, y = bill_length_mm, fill = species)) +
  geom_boxplot() + 
  theme_bw()

```

### Scatter plot

A scatter plot is a great way to visualize relationships and differences between variables and groups within your data sets. In our data set we detect that bill length seems to have a linear relationship with body mass.

```{r, warning=FALSE}
penguins %>%
  ggplot(aes(x = body_mass_g, y = bill_length_mm, color = species)) +
  geom_point() + 
  theme_bw()
```

### Correlation plot

An easy way to plot a correlation matrix is to use `ggcorrplot`.

```{r}
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower", lab = TRUE)

```

## Statistical calculations

### z-transformation


To apply a z-transformation in R we can use `scale`. This will set the mean to 0 and the standard deviation to 1. We can either replace our original value or create a new variable in our data set. With `head` we just look at the top of the tibble.

```{r}
penguins %>% 
  group_by(species) %>% 
  mutate(z_score_1 = scale(flipper_length_mm),
         z_score_2 = (flipper_length_mm - mean(flipper_length_mm, na.rm = TRUE))/sd(flipper_length_mm, na.rm = TRUE)) %>%
  dplyr::select(species, flipper_length_mm, z_score_1, z_score_2) %>%
  head() 

```

### Calculating probabilities using pnorm


By utilizing `pnorm`, we can determine the likelihood of values exceeding 0.2.

```{r}
pnorm(0.2, mean = 1, sd = 2, lower.tail = FALSE)

```

To calculate the probability that a bill length is equal to or less than 42.

```{r}
pnorm(42, mean(penguins$bill_length_mm, na.rm = TRUE), mean(penguins$bill_length_mm, na.rm = TRUE), lower.tail = TRUE)
```

We can do this for each species with `group_by`. Here we calculate the probability that a bill length is equal to or less than 42.

```{r}
penguins %>%
  group_by(species) %>%
  mutate(prob = pnorm(42,
                      mean = mean(bill_length_mm, na.rm = TRUE), 
                      sd = mean(bill_length_mm, na.rm = TRUE),
                      lower.tail = TRUE)) %>%
  distinct(species,prob) %>%
  kable(digits = 2)

```

### Manual confidence interval


A confidence interval is a range of values that is constructed from sample data and is used to estimate an unknown population parameter. It provides a measure of the uncertainty associated with the estimated parameter.

To calculate the confidence interval by hand we start by defining the confidence level and calculating n.\
By using `( )` around and `$` at end of our pipes we can access the vector which has removed all NA with `drop_na`.

```{r}
confidence_level <- 0.95

n <- length((penguins %>%
              dplyr::select(bill_length_mm) %>%
              drop_na)$bill_length_mm)
```

Calculate sample mean and standard deviation.

```{r}
bill_length_mean <- mean(penguins$bill_length_mm, na.rm = TRUE)
bill_length_sd <- sd(penguins$bill_length_mm, na.rm = TRUE)
```

Alternatively we can access our summary data frame if we are interested in only one species.\
With the `[ ]` we can access the first element of the means which corresponds to the Adélie species.

```{r}
bill_length_mean_adelie <- summary_stat$Mean_Bill_Length[1]
bill_length_sd_adelie <- summary_stat$SD_Bill_Length[1]
```

The next step is to define the standard error.

```{r}
standard_error <- bill_length_sd / sqrt(n)
```

We then compute the t-score related to the confidence level.\
First we set alpha as 1 - confidence level.\
Then we define our degrees of freedom as n - 1.

```{r}
alpha = 1 - confidence_level

degrees_of_freedom = n - 1

t_score = qt(p = alpha / 2, df = degrees_of_freedom, lower.tail= FALSE)
```

Calculate the margin error.

```{r}
margin_error <- t_score * standard_error
```

Now we can calculate and print the lower and upper bound confidence interval.

```{r}
lower_bound <- bill_length_mean - margin_error
upper_bound <- bill_length_mean + margin_error

```

To print text and stored variables we can use `cat`.

```{r}
cat("The", confidence_level * 100, "% confidence interval is [", lower_bound, ",", upper_bound, "].")
```

### One-Sample T-Test

If you have a single sample and want to test if its mean is significantly different from a hypothesized value, you can use `t_test`. The function calculates a t-statistic and provides a p-value.

Filter the data to only include Adélie penguins.

```{r}
adelie <- penguins %>%
  filter(species == "Adelie")
```

Perform a one-sample t-test on the body mass of Adélie penguins

```{r}
adelie %>%
  t_test(body_mass_g ~ 1) %>%
  kable()
```

### Two-Sample T-Test

If you have two independent samples and want to compare their means, you can use the `t_test` with two sample inputs. The function calculates a t-statistic and provides a p-value.

Filter the data to only include Adélie and Chinstrap penguins.

```{r}
adelie_chinstrap <- penguins %>%
  filter(species %in% c("Adelie", "Chinstrap"))
```

Perform a two-sample t-test on the body mass of Adélie and Chinstrap penguins.

```{r}
adelie_chinstrap %>%
  t_test(body_mass_g ~ species) %>%
  kable()
```

To inspect our result we can use ggplot. To plot the test significance on our plot we can use `stat_compare_means`.

```{r, warning = FALSE}
adelie_chinstrap %>%
  ggplot(aes(x = species, body_mass_g, fill = species)) +
  geom_boxplot() +
  theme_bw() +
  stat_compare_means(aes(label = after_stat(p.signif)), method = "t.test", ref.group = "Chinstrap")
```

### Chi-Square Test

If you have categorical data and want to test the independence of two variables, you can use the `chisq_test`. The function calculates a chi-square statistic and provides a p-value.

Perform a chi-square test on the species and island variables.

```{r}
table <- table(penguins$species, penguins$island)

table %>%
  chisq_test() %>%
  kable()
```

## Non-Normality

### Normality Tests

To see what normal data is supposed to look like, we start by randomly generate numbers with `rnorm`. We can specify what the mean and the standard deviation of the generated data should be.

```{r}
set.seed(42)

normal_data <- as.data.frame(rnorm(1000)) %>%
  rename(random_numbers = `rnorm(1000)`) 

normal_data %>%
  head(10) %>%
  kable(align = "l")
```

Now we create data that follows an exponential distribution with `rexp`.

```{r}
exp_data <- as.data.frame(rexp(1000, rate=3)) %>%
  rename(random_numbers = `rexp(1000, rate = 3)`)

exp_data %>%
  head(10) %>%
  kable(align = "l")
```

Create histograms for both data sets.

```{r}
normal_data %>%
  ggplot(aes(random_numbers)) +
  geom_histogram(color = "black",
                 fill = "steelblue",
                 bins = 25) +
  theme_bw()
```

```{r}
exp_data %>%
  ggplot(aes(random_numbers)) +
  geom_histogram(color = "black",
                 fill = "steelblue",
                 bins = 25) +
  theme_bw()
```

To analyze visually analyze normality we can create Q-Q plot for both data sets.

```{r}
normal_data %>%
  ggplot(aes(sample = random_numbers)) + 
           geom_qq_line(distribution = stats::qnorm) +
           geom_qq(color = "steelblue", distribution = stats::qnorm) + 
           xlab("Theoretical Quantiles") +
           ylab("Sample Quantiles") +
           theme_bw()
```

```{r}
exp_data %>%
  ggplot(aes(sample = random_numbers)) + 
           geom_qq_line(distribution = stats::qnorm) +
           geom_qq(color = "steelblue", distribution = stats::qnorm) + 
           xlab("Theoretical Quantiles") +
           ylab("Sample Quantiles") +
           theme_bw()
```

Perform shapiro-wilk test using `shapiro_test`. We can not reject the null hypothesis because p-value is smaller 0.05.

```{r}
normal_data %>%
  shapiro_test(random_numbers) %>%
  kable()
```

Perform shapiro-wilk test fo exponetial data using `shapiro.test`. We can reject the null hypothesis because p-value is lower than 0.05.

```{r}
exp_data %>%
  shapiro_test(random_numbers) %>%
  kable()
```

For sample size larger than 50 we should use the kolmogorov-smirnov test using `ks.test`. Because the p-value is less than 0.05, we can reject the null hypothesis. The sample data does not come from a normal distribution.

```{r}
ks.test(normal_data, 'pnorm')
ks.test(exp_data, 'pnorm')
```

### Normal Data: Analysis of Variance (ANOVA)

If you have multiple groups and want to test if their means are significantly different, you can use the function `aov` followed by the `summary` to obtain an analysis of variance table with p-values.

Filter the data to only include Adélie, Chinstrap, and Gentoo penguins.

```{r}
adelie_chinstrap_gentoo <- penguins %>%
  filter(species %in% c("Adelie", "Chinstrap", "Gentoo"))
```

Perform an ANOVA test on the body mass of Adélie, Chinstrap, and Gentoo penguins.

```{r}
adelie_chinstrap_gentoo %>% 
  anova_test(body_mass_g ~ species) %>%
  kable()
```

R package [rstatix](https://cran.r-project.org/web/packages/rstatix/rstatix.pdf%20https://rpkgs.datanovia.com/rstatix/) provides additional functions for Anova and repeated measures Anova

### Non-Normal Data: Mann-Whitney U Test (Mann-Whitney-Wilcoxon test, 2 Groups only)

The Mann-Whitney U test is used to compare two independent non-Normally distributed groups. In R, you can use the `wilcox_test` function to perform this test. By default, the option paired = FALSE for independent data. See [documentation](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/wilcox.test) for more details.

Filter the data to only include Adélie and Chinstrap penguins.

```{r}
adelie_chinstrap <-  penguins %>%
  filter(species %in% c("Adelie", "Chinstrap"))

```

Perform a Mann-Whitney U test on the body mass of Adélie and Chinstrap penguins.

```{r}
adelie_chinstrap %>% 
  wilcox_test(body_mass_g ~ species) %>%
  kable()
```

### Non-Normal Data: Kruskal-Wallis Test

The Kruskal-Wallis test is used to compare the distribution of more than two independent non-Normal groups. In R, you can use the `kruskal_test` to perform this test.

```{r}
penguins %>% 
  kruskal_test(body_mass_g ~ island) %>%
  kable()
```

### Multiple Comparison Corrections

When conducting multiple comparisons, it is important to account for the increased likelihood of obtaining false positives. One of the most commonly use corrections is the Bonferroni correction.

Normal data: To perform an Anova for pairwise group comparisons, with Bonferroni correction, use the function:


```{r}
treatment_outcome <- data.frame(
  treatment = rep(c("A", "B", "C"), each = 20),
  outcome = c(rnorm(20, mean = 2, sd =2),
              rnorm(20, mean = 6, sd = 4),
              rnorm(20, mean = 4, sd = 0.8)),
  patient_id = rep(1:20, times = 3))

treatment_outcome %>%
  pairwise_t_test(outcome ~ treatment, p.adjust.method = "bonferroni")
```

Non-Normal Data: To perform a Kruskal Wallis test with Bonferroni correction, use the Dunn Test with the option method. The Dunn Test performs the post hoc pairwise multiple comparisons procedure appropriate to follow up a Kruskal-Wallis test, which is a non-parametric analog of the one-way ANOVA.

```{r}
treatment_outcome_pois <- data.frame(
  treatment = rep(c("D", "E", "F"), each = 20),
  outcome = c(rpois(20, lambda = 0.1),
              rpois(20, lambda = 1),
              rpois(20, lambda = 6)))

treatment_outcome_pois %>% 
  kruskal_test(treatment ~ outcome) %>%
  kable()

treatment_outcome_pois %>% 
  dunn_test(treatment ~ outcome, p.adjust.method = "bonferroni") %>%
  head(10) %>%
  kable()
```

## Dependent Data

### Intraclass Correlation Coefficient ICC

One easy way to calculate the ICC is to first calculate an Anova table that renders the Sum Of Squares (SS) for the explanatory (or grouping or pairing) variable considered. The SS are the partition of the variability between groups/panels and within groups/panels. Then we can use the simple formula below to obtain the ICC.

Load the data self esteem from R package [datarium](https://rdrr.io/cran/datarium/man/selfesteem.html) . The data set contains 10 individuals' self-esteem score on three time points during a specific diet to determine whether their self-esteem improved.

```{r}
data("selfesteem", package = "datarium")
head(selfesteem, 5)

selfesteem <- selfesteem %>%
  gather(key = "time", value = "score", t1, t2, t3) %>%
  convert_as_factor(id, time)

head(selfesteem, 5) %>%
  kable()

```

For the ICC calculation, we are not interested in the differences over time. Note that we calculate the anova table just to obtain the SS's for the groups. In this case, the grouping variable is the id of every person.

```{r}
anova_table_se <- aov(score ~ id, data = selfesteem)
summary(anova_table_se)
```

```{r}
#ICC <- ss-between / (ss-between + ss-within)
ICC <- 4.57/(4.57+119.08)
cat("ICC is:",ICC)

```
In this case, the ICC is very small, so most of the variance is not at the person level but over time. There is a clear increasing trend over time.

Alternatively you can use `anova_test`.

```{r}
selfesteem %>%
  anova_test(score ~ id) %>%
  kable()
```


### Plotting Paired Data

R package [PairedData](https://cran.r-project.org/web/packages/PairedData/PairedData.pdf) provides functions to plot line-boxplots (profile plots), Bland-Altman plots and sliding chart plots

Bland-Altman plot to measure agreement between two methods:

```{r}
data("anscombe2")
with(anscombe2,plot(paired(X2,Y2),type="BA"))

```

### Non-Normal Paired 2 Groups Comparison: Wilcoxon Signed-Rank Test

Because paired data violate the assumption of data independence, we need to perform a non-parametric test, the Wilcoxon signed-rank test, with R function `wilcox.test` with the option paired = TRUE. This test only works for two groups.

[Example data set](http://www.sthda.com/english/wiki/paired-samples-wilcoxon-test-in-r): weight of the same 10 mice *before* and *after* a certain treatment.

First, we need to put the data into two numeric vectors

```{r}
# Weight of the mice before treatment
before <-c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, 205.2, 193.7)
# Weight of the mice after treatment
after <-c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, 392.3, 352.2)
# Create a data frame
my_data <- data.frame( 
                group = rep(c("before", "after"), each = 10),
                weight = c(before,  after))

```

```{r}
res <- wilcox.test(before, after, paired = TRUE)
res
```

Print only the p-value

```{r}
res$p.value
```

### Multiple Comparisons with Paired Data

R package rstatix provides a series of functions to work with paired data or repeated measures, several groups and correct for multiple comparisons.

```{r}
df <- ToothGrowth
df$dose <- as.factor(df$dose)

```

Use function t_test to obtain p-values corrected for multiple comparisons, here we set paired = t

```{r}
pairwise.test <- df %>% t_test(len ~ dose, paired = TRUE)
pairwise.test %>%
  kable()

df %>%
  ggboxplot(x = "dose", y = "len", fill = "steelblue") +
  stat_pvalue_manual(
    pairwise.test, label = "p.adj.signif", 
    y.position = c(29, 35, 39)) + theme_bw()
```